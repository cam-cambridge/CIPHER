{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr-Intern Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from reasoning_experiments.test_utils import *\n",
    "login(\n",
    "    token=\"...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Configurations\n",
    "Define different experimental setups with various model configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments={\n",
    "    'exp0':{'language':False,'vision':False,'expert':False,'lora':False,'RAG':False,'path':\"meta-llama/Llama-3.2-11B-Vision-Instruct\"},\n",
    "    'exp2':{'language':False,'vision':False,'expert':True,'lora':False,'RAG':False,'path':'/home/cm2161/rds/hpc-work/ex.2/checkpoint-279'},\n",
    "    # 'exp2+RAG':{'language':False,'vision':False,'expert':True,'lora':False,'RAG':True,'path':'/home/cm2161/rds/hpc-work/ex.2/checkpoint-279'},\n",
    "    # 'exp2+codebook':{'language':False,'vision':False,'expert':True,'lora':False,'codebook':True,'path':'/home/cm2161/rds/hpc-work/ex.2/checkpoint-279'},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model / datasets loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_model(experiment):\n",
    "    \n",
    "    model, processor, vision_expert = load_model_and_processor(\n",
    "        experiment,\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    return model, processor, vision_expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive control dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'reasoning_experiments/vanilla_control/prompt.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_experiments/vanilla_control/prompt.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      4\u001b[0m     prompt_template \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      6\u001b[0m tests \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/llama-manufacturing/pr-intern/.venv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'reasoning_experiments/vanilla_control/prompt.txt'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "with open(\"reasoning_experiments/vanilla_control/prompt.txt\", \"r\") as file:\n",
    "    prompt_template = file.read()\n",
    "\n",
    "tests = []\n",
    "for _ in range(100):\n",
    "    E = random.randint(30, 300) \n",
    "    F = random.randint(E-30, E+30)\n",
    "    ANSWER = (100 / E) * F\n",
    "\n",
    "    tests.append({\"context\":prompt_template.format(E=E, F=F), \"answer\":ANSWER})\n",
    "\n",
    "print(tests[0])\n",
    "\n",
    "naive_control_dataset = batchify(tests, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain questions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'How do thermal gradients during FDM printing affect residual stress in polymer parts?'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load domain questions from the JSON file\n",
    "with open(\"reasoning_experiments/domain_knowledge/3d_printing_questions.json\", \"r\") as file:\n",
    "    domain_questions = json.load(file)[\"questions\"]\n",
    "\n",
    "# Prepare the dataset for evaluation\n",
    "domain_qs = []\n",
    "for question in domain_questions:\n",
    "    domain_qs.append({\"question\": question})  # Placeholder for answers\n",
    "\n",
    "print(domain_qs[0])\n",
    "\n",
    "domain_questions_dataset = batchify(domain_qs, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emerging capabilities dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Given Information:\\n    estimated_flowrate = 85%\\n    firmware_flowrate = 100%\\n    material = ABS\\n    current_temperature = 220°C\\n    feed_rate = 1200 mm/s\\n\\nAnalyse the given information and select the most relevant adjustment.\\nPay attention to the validity of your statements!\\nWhile changing the extrusion flow rate may seem the best option, it is not always the best option.\\n    Consider physics, material properties, the current temperature and other things you know about additive manufacturing.\\nSuggest a single G-code command for the most effective parameter adjustment, if an adjustment is needed.\\n\\n**Output the gcode command in the gcode tag in this format: ```gcode <command>```**\\n    No other information should be within the gcode tag. Do not change lines either.\\n    If a command is not needed, just say ```gcode no_command```.\\n    If a command is needed, provide the G-code command within the ```gcode <command>``` tags.\\n'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"reasoning_experiments/emerging_control/prompt.txt\", \"r\") as file:\n",
    "    prompt_template = file.read()\n",
    "\n",
    "with open(\"reasoning_experiments/emerging_control/system_command.txt\", \"r\") as file:\n",
    "    system_message = file.read()\n",
    "\n",
    "# Load case tests from the JSON file\n",
    "with open(\"reasoning_experiments/emerging_control/case_tests.json\", \"r\") as file:\n",
    "    case_tests = json.load(file)\n",
    "\n",
    "playbook = {    \"M104 - Set Hotend Temperature\": {\n",
    "    \"function\": \"M104\",\n",
    "    \"description\": \"Set a new target hot end temperature.\",\n",
    "    \"hyperlink\": \"https://marlinfw.org/docs/gcode/M104.html\"\n",
    "    },\n",
    "\n",
    "    \"M106 - Set Fan Speed\": {\n",
    "    \"function\": \"M106\",\n",
    "    \"description\": \"Turn on fan and set speed\",\n",
    "    \"hyperlink\": \"https://marlinfw.org/docs/gcode/M106.html\"\n",
    "    },\n",
    "\n",
    "    \"M220 - Set Feed rate\": {\n",
    "    \"function\": \"M220\",\n",
    "    \"description\": \"Set the feed rate for the extruder.\",\n",
    "    \"hyperlink\": \"https://marlinfw.org/docs/gcode/M220.html\"\n",
    "    },\n",
    "\n",
    "    \"M221 - Set Extrusion Flow Rate\": {\n",
    "    \"function\": \"M221\",\n",
    "    \"description\": \"Set the extrusion flow rate for the extruder.\",\n",
    "    \"hyperlink\": \"https://marlinfw.org/docs/gcode/M221.html\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_entry_by_gcode(gcode_command):\n",
    "    for key, entry in playbook.items():\n",
    "        if entry['function'] == gcode_command:\n",
    "            return entry[\"hyperlink\"]\n",
    "    return None \n",
    "\n",
    "def format_scenario(scenario):\n",
    "    scenario_info = f\"\"\"Given Information:\n",
    "    estimated_flowrate = {scenario['Given Information']['estimated_flowrate']}\n",
    "    firmware_flowrate = {scenario['Given Information']['firmware_flowrate']}\n",
    "    material = {scenario['Given Information']['material']}\n",
    "    current_temperature = {scenario['Given Information']['current_temperature']}\n",
    "    feed_rate = {scenario['Given Information']['feed_rate']}\"\"\"\n",
    "\n",
    "    prompt = prompt_template.replace(\"{system}\", scenario_info)\n",
    "    return prompt\n",
    "\n",
    "scenarios = []\n",
    "for scenario in case_tests:\n",
    "    scenario = format_scenario(scenario)\n",
    "    scenarios.append({\"question\":scenario})\n",
    "\n",
    "case_control_dataset = batchify(scenarios, batch_size=1)\n",
    "print(case_control_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_gcode_details(hyperlink):\n",
    "    response = requests.get(hyperlink)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        details = soup.select_one('body > div.container.detail > div > div.col-lg-9.col-md-8.main')\n",
    "        return details.text if details else \"No details found\"\n",
    "    else:\n",
    "        return f\"Error fetching details: {response.status_code}\"\n",
    "\n",
    "# Load the G-code playbook\n",
    "with open('/home/cm2161/Documents/llama-manufacturing/pr-intern/reasoning_experiments/emerging_control/gcode_playbook.json') as f:\n",
    "    gcode_playbook = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Naive Control, Llama, Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# experiment_results = {}\n",
    "\n",
    "# for key, value in experiments.items():\n",
    "#     print(f\"Validating: {key}\")\n",
    "\n",
    "#     # Load and prepare model components\n",
    "#     model, processor, vision_expert = load_and_prepare_model(value)\n",
    "\n",
    "#     # Test 1: Naive-control dataset evaluation\n",
    "#     experiment_answers = []\n",
    "#     experiment_answers_original = []\n",
    "#     for batch in tqdm(naive_control_dataset, desc=\"Processing domain control batches\"):\n",
    "#         with torch.no_grad():\n",
    "#             # Prepare batch\n",
    "#             batch_collated = val_collate_fn_text(\n",
    "#                 batch, \n",
    "#                 processor\n",
    "#             ).to(model.device)\n",
    "\n",
    "#             # Generate outputs\n",
    "#             outputs = model.generate(\n",
    "#                 **batch_collated,\n",
    "#                 max_new_tokens=1024,\n",
    "#                 temperature=0.2\n",
    "#             )\n",
    "\n",
    "#             # Process results\n",
    "#             decoded_outputs = map(processor.decode, outputs)\n",
    "#             answers = answer_extractor(decoded_outputs)\n",
    "#             answers = [round(float(answer.split('<M221 S')[1].split('>')[0]), 2) for answer in answers]\n",
    "#             original_answers = [round(float(item['answer']), 2) for item in batch]\n",
    "\n",
    "#             experiment_answers.extend(answers)\n",
    "#             experiment_answers_original.extend(original_answers)\n",
    "\n",
    "#             # Save vision results\n",
    "#             results_df = pd.DataFrame({\n",
    "#                 'answers': experiment_answers,\n",
    "#                 'answers_original': experiment_answers_original,\n",
    "#             })\n",
    "#             results_df.to_csv(f'reasoning_experiments/naive_control_experiment_results_{key}.csv',\n",
    "#                             index=True,\n",
    "#                             index_label='control_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test domain expertise, Llama, Ours, Ours+RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# for key, value in experiments.items():\n",
    "\n",
    "#     results = []\n",
    "\n",
    "#     print(f\"Validating: {key}\")\n",
    "\n",
    "#     # Load and prepare model components\n",
    "#     model, processor, vision_expert = load_and_prepare_model(value)\n",
    "\n",
    "#     # Test 2: Domain-specific QA evaluation\n",
    "#     for batch in tqdm(domain_questions_dataset, desc=\"Processing domain questions batches\"):\n",
    "#         with torch.no_grad():\n",
    "#             # Prepare batch\n",
    "#             batch_collated = val_collate_fn(\n",
    "#                 batch, \n",
    "#                 processor,\n",
    "#                 RAG = True if value['RAG'] else False\n",
    "#                 ).to(model.device)\n",
    "\n",
    "#             # Generate outputs\n",
    "#             outputs = model.generate(\n",
    "#                 **batch_collated,\n",
    "#                 max_new_tokens=1024,\n",
    "#                 temperature=0.2\n",
    "#             )\n",
    "            \n",
    "#             decoded_outputs = map(processor.decode, outputs)\n",
    "#             answers = answer_extractor(decoded_outputs)\n",
    "\n",
    "#             for example, answer in zip(batch, answers):\n",
    "#                 question = example['question']\n",
    "#                 results.append({\n",
    "#                     \"questions\": question,\n",
    "#                     \"answer\": answer\n",
    "#                 })\n",
    "\n",
    "#     # Write the results to a JSON file\n",
    "#     with open(f'reasoning_experiments/domain_expertise_experiment_results_{key}.json', \"w\") as file:\n",
    "#         json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test emerging capabilities, Llama, Ours, Ours+Codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating: exp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33732b58b5664cf0bb90462d2d260f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing emerging capabilities batches:  20%|█████████                                    | 10/50 [01:16<04:52,  7.32s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for key, value in experiments.items():\n",
    "    \n",
    "    results = []\n",
    "    print(f\"Validating: {key}\")\n",
    "\n",
    "    # Load and prepare model components\n",
    "    model, processor, vision_expert = load_and_prepare_model(value)\n",
    "\n",
    "    # Test 3: Emerging capabilities evaluation\n",
    "    for batch in tqdm(case_control_dataset, desc=\"Processing emerging capabilities batches\"):\n",
    "\n",
    "        with open(\"reasoning_experiments/emerging_control/system_command.txt\", \"r\") as file:\n",
    "            system_message = file.read()\n",
    "\n",
    "        # print(\"Given information:\", batch[0]['question'])\n",
    "\n",
    "        for step in [0]:\n",
    "            \n",
    "            if step == 1:\n",
    "\n",
    "                ### RAG\n",
    "                embedding = generate_RAG_embedding(answers[0])\n",
    "                if embedding is not None:\n",
    "                    similarities = []\n",
    "                    for fact in processed_facts:\n",
    "                        embedding_array = np.array(embedding)  # Convert to NumPy array\n",
    "                        embedding_reshaped = embedding_array.reshape(1, -1)  # Reshape to 2D\n",
    "                        similarity = cosine_similarity(embedding_reshaped, np.array(fact['embedding']).reshape(1, -1))\n",
    "                        similarities.append(similarity)\n",
    "\n",
    "                # Keep N most relevant facts\n",
    "                N = 5  # Set the number of relevant facts to keep\n",
    "                top_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:N]\n",
    "                relevant_facts = [processed_facts[i] for i in top_indices]\n",
    "                relevant_facts_string = \"\\n| \".join([fact['original_fact'] for fact in relevant_facts])\n",
    "                system_message += f\"\\n\\nMore relevant information: {relevant_facts_string}\"\n",
    "\n",
    "                ### Codebook\n",
    "                try:                \n",
    "                    gcode_command = answers[0].split('gcode')[1].split('```')[0]\n",
    "                    gcode_command = gcode_command.strip().split(\" \")[0]\n",
    "                    gcode_info = get_entry_by_gcode(gcode_command)\n",
    "                    details= fetch_gcode_details(gcode_info)\n",
    "                    system_message += f\"\\n\\nMore relevant information: {details}\"\n",
    "                except:\n",
    "                    system_message+=\"It is likely that the G-code command is not needed.\"\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Prepare batch\n",
    "                batch_collated = val_collate_fn(\n",
    "                    batch, \n",
    "                    processor,\n",
    "                    system_message=system_message\n",
    "                    ).to(model.device)\n",
    "    \n",
    "                # Generate outputs\n",
    "                outputs = model.generate(\n",
    "                    **batch_collated,\n",
    "                    max_new_tokens=200,\n",
    "                    temperature=0.1\n",
    "                )\n",
    "                decoded_outputs = map(processor.decode, outputs)\n",
    "                answers = answer_extractor(decoded_outputs)\n",
    "\n",
    "                try:\n",
    "                    gcode_commands = answers.split('```gcode')[1].split('```')[0]\n",
    "                    print(gcode_commands)\n",
    "                except:\n",
    "                    gcode_command = None\n",
    "\n",
    "        for example, answer in zip(batch, answers):\n",
    "            question = example['question']\n",
    "            results.append({\n",
    "                \"questions\": question,\n",
    "                \"command\": gcode_command,\n",
    "                \"answer\": answer\n",
    "            })\n",
    "\n",
    "    # Write the results to a JSON file\n",
    "    with open(f'reasoning_experiments/emerging_control_experiment_results_{key}', \"w\") as file:\n",
    "        json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1574.8x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a single figure for all bar charts\n",
    "fig, ax = plt.subplots(figsize=(1.5748, 1), dpi=1000)\n",
    "\n",
    "# Store errors for all experiments\n",
    "all_errors = []\n",
    "all_std_errors = []  # To store standard errors\n",
    "labels = []\n",
    "\n",
    "for key in [ \"gpt4o-mini\", \"exp0\", \"exp2\",]:\n",
    "    # Load results\n",
    "    results_df = pd.read_csv(f'/home/cm2161/Documents/llama-manufacturing/pr-intern/reasoning_experiments/vanilla_control/naive_control_experiment_results_{key}.csv')\n",
    "    errors = np.abs(results_df['answers'] - results_df['answers_original'])\n",
    "    all_errors.append(errors.mean())  # Use mean error for bar height\n",
    "    all_std_errors.append(errors.std()*0.5)  # Use std error for error bars\n",
    "    labels.append(f\"ex.{key[-1]}\")\n",
    "\n",
    "# Create bar chart with error bars\n",
    "ax.bar(\n",
    "    labels, \n",
    "    all_errors, \n",
    "    yerr=all_std_errors,  # Add standard error bars\n",
    "    capsize=1, \n",
    "    width=0.6, \n",
    "    linewidth=0.5,              # Line thickness for bars\n",
    "    error_kw={'elinewidth': 0.5, 'capthick': 0.5},  # Error bar style\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['left'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['top'].set_visible(True)\n",
    "\n",
    "# Set x-ticks and labels\n",
    "ax.tick_params(axis='x', bottom=True, labelbottom=False)  # Remove x-ticks and labels\n",
    "ax.tick_params(axis='both', labelsize=5, width=0.5,  length=2)  # Tick line thickness\n",
    "\n",
    "# Adjust border thickness\n",
    "tick_lines = ['top', 'bottom', 'left', 'right']\n",
    "for spine in tick_lines:\n",
    "    ax.spines[spine].set_linewidth(0.5)\n",
    "\n",
    "# Remove any padding\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store accuracies and std for all experiments\n",
    "all_accuracies = []\n",
    "all_stds = []\n",
    "labels = []\n",
    "\n",
    "def bootstrap_accuracy(y_true, y_pred, n_iterations=1000):\n",
    "    accuracies = []\n",
    "    n_samples = len(y_true)\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        # Random sampling with replacement\n",
    "        indices = np.random.randint(0, n_samples, n_samples)\n",
    "        boot_true = y_true.iloc[indices]\n",
    "        boot_pred = y_pred.iloc[indices]\n",
    "        \n",
    "        # Calculate accuracy for this bootstrap sample\n",
    "        accuracy = (boot_true == boot_pred).mean() * 100\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    return np.mean(accuracies), np.std(accuracies)\n",
    "\n",
    "for key in experiments.keys():\n",
    "    # Load results\n",
    "    results_df = pd.read_csv(f'/home/cm2161/Documents/llama-manufacturing/pr-intern/experiments/caxton/caxton_experiment_results_{key}.csv')\n",
    "    \n",
    "    if 'y_class' in results_df.columns and 'y_class_hat' in results_df.columns:\n",
    "        # Calculate accuracy and std using bootstrapping\n",
    "        mean_acc, std_acc = bootstrap_accuracy(\n",
    "            results_df['y_class'], \n",
    "            results_df['y_class_hat']\n",
    "        )\n",
    "        all_accuracies.append(mean_acc)\n",
    "        all_stds.append(std_acc)\n",
    "        labels.append(f\"ex.{key[-1]}\")\n",
    "\n",
    "# Create figure with broken axis\n",
    "mm_to_inches = 0.0393701\n",
    "fig_size_inches = 33 * mm_to_inches\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, \n",
    "                              figsize=(fig_size_inches, fig_size_inches), \n",
    "                              dpi=1200,\n",
    "                              gridspec_kw={'width_ratios': [1, 1], 'wspace': 0.05})\n",
    "\n",
    "# Plot in both axes with error bars\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.barh(labels, all_accuracies, \n",
    "            height=0.5,\n",
    "            xerr=all_stds,\n",
    "            color='lightgrey',\n",
    "            edgecolor='black',\n",
    "            linewidth=0.5,\n",
    "            error_kw={'ecolor': 'black', \n",
    "                     'capsize': 2, \n",
    "                     'capthick': 0.5, \n",
    "                     'elinewidth': 0.5})\n",
    "    \n",
    "    # Style plot\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "# Add white spine between broken axes\n",
    "ax1.spines['right'].set_visible(True)\n",
    "ax1.spines['right'].set_color('white')\n",
    "\n",
    "# Set different limits for each axis\n",
    "ax1.set_xlim(0, 40)  # First segment shows 0-30\n",
    "ax2.set_xlim(70, 100)  # Second segment shows 70-100\n",
    "\n",
    "ax1.set_xticks([0.1, 10, 20, 30, 39.5])\n",
    "ax1.set_xticklabels([])  # Remove x-axis labels\n",
    "ax1.tick_params(axis='x', length=0)  # Remove tick marks\n",
    "ax1.grid(True, axis='x', linestyle='-', color='lightgrey', linewidth=0.25, alpha=1, zorder=0)\n",
    "ax1.set_axisbelow(True)\n",
    "\n",
    "ax2.set_xticks([70.1, 80, 90, 99.5])\n",
    "ax2.set_xticklabels([])  # Remove x-axis labels\n",
    "ax2.tick_params(axis='x', length=0)  # Remove tick marks\n",
    "ax2.grid(True, axis='x', linestyle='-', color='lightgrey', linewidth=0.25, alpha=1)\n",
    "ax2.set_axisbelow(True)\n",
    "\n",
    "# Replace plt.tight_layout(pad=0) with:\n",
    "plt.subplots_adjust(\n",
    "    left=0,    # Remove left margin\n",
    "    right=1,   # Remove right margin\n",
    "    bottom=0,  # Remove bottom margin\n",
    "    top=1,     # Remove top margin\n",
    "    wspace=0.1 # Keep small spacing between subplots\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU Node)",
   "language": "python",
   "name": "gpu_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
